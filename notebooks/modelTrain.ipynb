{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5589e518-eda3-494f-9f59-078439bf643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a2e681f-896a-4f68-afe3-39ce815a7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/yield_climate_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e08b0aa3-5b92-4379-9baa-f2aeb80b6d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>crop</th>\n",
       "      <th>year</th>\n",
       "      <th>yield_kg_ha</th>\n",
       "      <th>t2m</th>\n",
       "      <th>rad</th>\n",
       "      <th>rh2m</th>\n",
       "      <th>precip</th>\n",
       "      <th>lag_yield_kg_ha</th>\n",
       "      <th>crop_encoded</th>\n",
       "      <th>country_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>2002</td>\n",
       "      <td>2590.6</td>\n",
       "      <td>17.874615</td>\n",
       "      <td>22.388462</td>\n",
       "      <td>41.238462</td>\n",
       "      <td>8.14</td>\n",
       "      <td>2570.8</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Maize (corn)</td>\n",
       "      <td>2002</td>\n",
       "      <td>9514.2</td>\n",
       "      <td>13.202308</td>\n",
       "      <td>16.440769</td>\n",
       "      <td>64.092308</td>\n",
       "      <td>16.55</td>\n",
       "      <td>9720.8</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Somalia</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>2002</td>\n",
       "      <td>373.6</td>\n",
       "      <td>28.020000</td>\n",
       "      <td>22.956923</td>\n",
       "      <td>54.958462</td>\n",
       "      <td>9.11</td>\n",
       "      <td>365.4</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>Maize (corn)</td>\n",
       "      <td>2002</td>\n",
       "      <td>2851.6</td>\n",
       "      <td>17.874615</td>\n",
       "      <td>22.388462</td>\n",
       "      <td>41.238462</td>\n",
       "      <td>8.14</td>\n",
       "      <td>2437.1</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>Rice</td>\n",
       "      <td>2002</td>\n",
       "      <td>2356.3</td>\n",
       "      <td>17.874615</td>\n",
       "      <td>22.388462</td>\n",
       "      <td>41.238462</td>\n",
       "      <td>8.14</td>\n",
       "      <td>2285.7</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7932</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>Sugar cane</td>\n",
       "      <td>2023</td>\n",
       "      <td>50682.0</td>\n",
       "      <td>26.443077</td>\n",
       "      <td>18.701538</td>\n",
       "      <td>83.175385</td>\n",
       "      <td>83.57</td>\n",
       "      <td>57011.1</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7933</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>2023</td>\n",
       "      <td>4553.8</td>\n",
       "      <td>21.551538</td>\n",
       "      <td>21.309231</td>\n",
       "      <td>54.147692</td>\n",
       "      <td>26.88</td>\n",
       "      <td>5154.2</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>China, mainland</td>\n",
       "      <td>Rice</td>\n",
       "      <td>2023</td>\n",
       "      <td>7136.8</td>\n",
       "      <td>7.953077</td>\n",
       "      <td>16.070000</td>\n",
       "      <td>60.429231</td>\n",
       "      <td>16.66</td>\n",
       "      <td>7079.6</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>China, mainland</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>2023</td>\n",
       "      <td>5781.1</td>\n",
       "      <td>7.953077</td>\n",
       "      <td>16.070000</td>\n",
       "      <td>60.429231</td>\n",
       "      <td>16.66</td>\n",
       "      <td>5855.4</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7936</th>\n",
       "      <td>Congo</td>\n",
       "      <td>Rice</td>\n",
       "      <td>2023</td>\n",
       "      <td>576.5</td>\n",
       "      <td>25.282308</td>\n",
       "      <td>16.840000</td>\n",
       "      <td>87.491538</td>\n",
       "      <td>71.48</td>\n",
       "      <td>578.8</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7937 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              country          crop  year  yield_kg_ha        t2m        rad  \\\n",
       "0        South Africa         Wheat  2002       2590.6  17.874615  22.388462   \n",
       "1               Spain  Maize (corn)  2002       9514.2  13.202308  16.440769   \n",
       "2             Somalia         Wheat  2002        373.6  28.020000  22.956923   \n",
       "3        South Africa  Maize (corn)  2002       2851.6  17.874615  22.388462   \n",
       "4        South Africa          Rice  2002       2356.3  17.874615  22.388462   \n",
       "...               ...           ...   ...          ...        ...        ...   \n",
       "7932        Sri Lanka    Sugar cane  2023      50682.0  26.443077  18.701538   \n",
       "7933         Zimbabwe         Wheat  2023       4553.8  21.551538  21.309231   \n",
       "7934  China, mainland          Rice  2023       7136.8   7.953077  16.070000   \n",
       "7935  China, mainland         Wheat  2023       5781.1   7.953077  16.070000   \n",
       "7936            Congo          Rice  2023        576.5  25.282308  16.840000   \n",
       "\n",
       "           rh2m  precip  lag_yield_kg_ha  crop_encoded  country_encoded  \n",
       "0     41.238462    8.14           2570.8             3               85  \n",
       "1     64.092308   16.55           9720.8             0               86  \n",
       "2     54.958462    9.11            365.4             3               84  \n",
       "3     41.238462    8.14           2437.1             0               85  \n",
       "4     41.238462    8.14           2285.7             1               85  \n",
       "...         ...     ...              ...           ...              ...  \n",
       "7932  83.175385   83.57          57011.1             2               87  \n",
       "7933  54.147692   26.88           5154.2             3              102  \n",
       "7934  60.429231   16.66           7079.6             1               22  \n",
       "7935  60.429231   16.66           5855.4             3               22  \n",
       "7936  87.491538   71.48            578.8             1               24  \n",
       "\n",
       "[7937 rows x 11 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8fc1011d-2368-40ce-a0ea-8cd22ee3c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort for safety\n",
    "data = data.sort_values(\"year\")\n",
    "\n",
    "# Time-based split\n",
    "train = data[data['year'] <= 2016]\n",
    "test = data[(data['year'] > 2016) & (data['year'] < 2023)]\n",
    "testF = data[data['year'] == 2023] #testFuture\n",
    "\n",
    "features = ['t2m', 'precip', 'rad', 'rh2m', 'lag_yield_kg_ha',\n",
    "            'crop_encoded', 'country_encoded']\n",
    "\n",
    "target = 'yield_kg_ha'\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test[target]\n",
    "\n",
    "X_F = testF[features]\n",
    "y_F = testF[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9db691eb-b687-43eb-a5d9-32b729a31ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse:  25779.27179341047\n",
      "Linear Regression R2 without lag = 0.09458110555508081\n"
     ]
    }
   ],
   "source": [
    "features_no_lag = ['t2m','precip','rad','rh2m','crop_encoded','country_encoded']\n",
    "\n",
    "#-----------------LINEAR REGRESSION without lag-yield -----------------------------\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(train[features_no_lag], train[target])\n",
    "pred = lr.predict(test[features_no_lag])\n",
    "\n",
    "print(\"rmse: \", mean_squared_error(test[target], pred)**0.5)\n",
    "print(\"Linear Regression R2 without lag =\", r2_score(test[target], pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "249cb8f9-b320-4b4e-909a-5d88596301ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1127\n",
      "[LightGBM] [Info] Number of data points in the train set: 5423, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 16554.123830\n",
      "LightGBM  RMSE: 5517.506326987455\n",
      "LightGBM  R2  : 0.9585242792105777\n",
      "XGB  RMSE: 5517.506326987455\n",
      "XGB  R2  : 0.9585242792105777\n"
     ]
    }
   ],
   "source": [
    "# --------------------------LightGBM without lag-yield------------------------\n",
    "lgbmNL = LGBMRegressor(\n",
    "    n_estimators=700,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgbmNL.fit(train[features_no_lag], train[target])\n",
    "\n",
    "y_pred_lgbm = lgbmNL.predict(test[features_no_lag])\n",
    "mse_lgbm = mean_squared_error(test[target], y_pred_lgbm)\n",
    "rmse_lgbm = mse_lgbm ** 0.5\n",
    "r2_lgbm = r2_score(test[target], y_pred_lgbm)\n",
    "\n",
    "print(\"LightGBM  RMSE:\", rmse_lgbm)\n",
    "print(\"LightGBM  R2  :\", r2_lgbm)\n",
    "\n",
    "# --------------------------XGBoost without lag-yield------------------------\n",
    "xgbNL = XGBRegressor(\n",
    "    n_estimators=700,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"  \n",
    ")\n",
    "\n",
    "xgbNL.fit(train[features_no_lag], train[target])\n",
    "\n",
    "y_pred_xgb = xgbNL.predict(test[features_no_lag])\n",
    "mse_xgb = mean_squared_error(test[target], y_pred_lgbm)\n",
    "rmse_xgb = mse_xgb ** 0.5\n",
    "r2_xgb = r2_score(test[target], y_pred_lgbm)\n",
    "\n",
    "print(\"XGB  RMSE:\", rmse_lgbm)\n",
    "print(\"XGB  R2  :\", r2_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cb67a59e-aee4-4c84-a13e-edb3d7f2846a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5423, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 16554.123830\n",
      "\n",
      "LightGBM  RMSE          : 3126.352459177482\n",
      "LightGBM  R2            : 0.9866836825909822\n",
      "\n",
      "LightGBM  RMSE for 2023 : 2847.710300815933\n",
      "LightGBM R2 for 2023    : 0.9890256308280415\n"
     ]
    }
   ],
   "source": [
    "# ----------------- LightGBM -----------------\n",
    "lgbm = LGBMRegressor(\n",
    "    n_estimators=700,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "lr = LinearRegression()\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgbm = lgbm.predict(X_test)\n",
    "mse_lgbm = mean_squared_error(y_test, y_pred_lgbm)\n",
    "rmse_lgbm = mse_lgbm ** 0.5\n",
    "r2_lgbm = r2_score(y_test, y_pred_lgbm)\n",
    "\n",
    "print(\"\\nLightGBM  RMSE          :\", rmse_lgbm)\n",
    "print(\"LightGBM  R2            :\", r2_lgbm)\n",
    "\n",
    "#for 2023\n",
    "pred2023 = lgbm.predict(X_F)\n",
    "print(\"\\nLightGBM  RMSE for 2023 :\", mean_squared_error(y_F,pred2023)**0.5)\n",
    "print(\"LightGBM R2 for 2023    :\", r2_score(y_F, pred2023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e7f400b-191b-43f4-a1e3-5d53a11ae562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost  RMSE          : 3126.352459177482\n",
      "XGBoost  R2            : 0.9866836825909822\n",
      "\n",
      "XGBoost  RMSE for 2023 : 2620.8141955202623\n",
      "XGBoost R2 for 2023    : 0.9907047640575919\n"
     ]
    }
   ],
   "source": [
    "# ----------------- XGBoost -----------------\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=700,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"   # fast\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = mse_xgb ** 0.5\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"XGBoost  RMSE          :\", rmse_lgbm)\n",
    "print(\"XGBoost  R2            :\", r2_lgbm)\n",
    "\n",
    "#for 2023\n",
    "pred2023 = xgb.predict(X_F)\n",
    "print(\"\\nXGBoost  RMSE for 2023 :\", mean_squared_error(y_F,pred2023)**0.5)\n",
    "print(\"XGBoost R2 for 2023    :\", r2_score(y_F, pred2023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b99b54a-2820-43b1-a343-701fac1286a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using LightGBM as the main model for SHAP and interpretation.\n"
     ]
    }
   ],
   "source": [
    "if r2_lgbm >= r2_xgb:\n",
    "    best_model = lgbm\n",
    "    best_name = \"LightGBM\"\n",
    "else:\n",
    "    best_model = xgb\n",
    "    best_name = \"XGBoost\"\n",
    "\n",
    "print(f\"\\nUsing {best_name} as the main model for SHAP and interpretation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "49077d05-7beb-475d-830d-3ceaa12f3c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP sample size: 1000\n",
      "Saved: shap_summary_global.png\n",
      "Saved: shap_dependence_precip.png\n",
      "Saved: shap_dependence_t2m.png\n",
      "Saved: shap_dependence_lag_yield.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#rechecking order\n",
    "feature_names = ['t2m', 'precip', 'rad', 'rh2m',\n",
    "                 'lag_yield_kg_ha', 'crop_encoded', 'country_encoded']\n",
    "\n",
    "# Rebuild X_test (just to be safe)\n",
    "X_test = X_test[feature_names]\n",
    "\n",
    "# Take a subsample of test data for SHAP\n",
    "X_shap = X_test.copy()\n",
    "if len(X_shap) > 1000:\n",
    "    X_shap = X_shap.sample(1000, random_state=12)\n",
    "\n",
    "print(\"SHAP sample size:\", len(X_shap))\n",
    "\n",
    "# 1. Build TreeExplainer and compute SHAP values ----\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_shap)\n",
    "\n",
    "# Convert to DataFrame for nicer handling\n",
    "X_shap_df = pd.DataFrame(X_shap, columns=feature_names)\n",
    "\n",
    "# 2. Global feature importance (summary plot) ----\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_shap_df, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/shap_summary_global.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved: shap_summary_global.png\")\n",
    "\n",
    "# 3. Dependence plot: precipitation vs yield effect ----\n",
    "plt.figure()\n",
    "shap.dependence_plot('precip', shap_values, X_shap_df, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/shap_dependence_precip.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved: shap_dependence_precip.png\")\n",
    "\n",
    "# ---- 4. Dependence plot: temperature vs yield effect ----\n",
    "plt.figure()\n",
    "shap.dependence_plot('t2m', shap_values, X_shap_df, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/shap_dependence_t2m.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved: shap_dependence_t2m.png\")\n",
    "\n",
    "# ---- 5. Dependence plot: lag_yield (very important feature) ----\n",
    "plt.figure()\n",
    "shap.dependence_plot('lag_yield_kg_ha', shap_values, X_shap_df, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/shap_dependence_lag_yield.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved: shap_dependence_lag_yield.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "820a6ce4-e62e-478a-9cd2-9d6662a932e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           feature  mean_abs_shap\n",
      "4  lag_yield_kg_ha   16854.524712\n",
      "5     crop_encoded    3663.188558\n",
      "2              rad     435.047870\n",
      "6  country_encoded     340.295318\n",
      "0              t2m     294.129820\n",
      "1           precip     291.440173\n",
      "3             rh2m     219.224955\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# shap_values is (n_samples, n_features)\n",
    "importance = np.mean(np.abs(shap_values), axis=0)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": importance\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bdf5bb89-e0f9-46ee-9a44-c85bcc444026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           feature  normalized_importance\n",
      "4  lag_yield_kg_ha               0.762722\n",
      "5     crop_encoded               0.165771\n",
      "2              rad               0.019687\n",
      "6  country_encoded               0.015399\n",
      "0              t2m               0.013310\n",
      "1           precip               0.013189\n",
      "3             rh2m               0.009921\n"
     ]
    }
   ],
   "source": [
    "normalized = importance / importance.sum()\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"normalized_importance\": normalized\n",
    "}).sort_values(\"normalized_importance\", ascending=False)\n",
    "\n",
    "\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df1219c-afe1-4138-9456-366d63eaf412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
